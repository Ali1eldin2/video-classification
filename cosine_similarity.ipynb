{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f64e6d7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding no_theft: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 531/531 [01:07<00:00,  7.92it/s]\n",
      "Embedding store_theft: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 324/324 [00:56<00:00,  5.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Collected embeddings for 855 videos.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking duplicates: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 855/855 [00:02<00:00, 400.55it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Unique videos kept: 637 / 855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying unique videos: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 637/637 [00:00<00:00, 806.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸŽ‰ Finished! Unique videos saved in: new_dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "\n",
    "# ================= CONFIG =================\n",
    "input_root = \"dataset\"          # original dataset root (e.g., with class folders)\n",
    "output_root = \"new_dataset\"     # folder to save non-duplicates\n",
    "num_sample_frames = 8           # how many frames to sample per video\n",
    "similarity_threshold = 0.9999     # similarity cutoff to consider duplicates\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# ==========================================\n",
    "\n",
    "# Pretrained ResNet18 feature extractor\n",
    "resnet = models.resnet18(pretrained=True)\n",
    "resnet.fc = nn.Identity()  # remove final classification layer\n",
    "resnet = resnet.to(device)\n",
    "resnet.eval()\n",
    "\n",
    "# Image transform\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "def get_video_embedding(video_path, num_frames=8):\n",
    "    \"\"\"Extract a compact embedding for the entire video.\"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    if total_frames <= 0:\n",
    "        cap.release()\n",
    "        return None\n",
    "\n",
    "    indices = np.linspace(0, total_frames - 1, num_frames, dtype=int)\n",
    "    feats = []\n",
    "\n",
    "    for idx in indices:\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, idx)\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            continue\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        img = Image.fromarray(frame)\n",
    "        img_t = transform(img).unsqueeze(0).to(device)\n",
    "        with torch.no_grad():\n",
    "            feat = resnet(img_t).squeeze().cpu()\n",
    "        feats.append(feat)\n",
    "\n",
    "    cap.release()\n",
    "    if len(feats) == 0:\n",
    "        return None\n",
    "    return torch.stack(feats).mean(dim=0)\n",
    "\n",
    "def ensure_dir(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "# Collect all videos and embeddings\n",
    "video_info = []  # [(video_path, class_name, emb)]\n",
    "classes = [d for d in os.listdir(input_root) if os.path.isdir(os.path.join(input_root, d))]\n",
    "\n",
    "for cls in classes:\n",
    "    class_dir = os.path.join(input_root, cls)\n",
    "    videos = [v for v in os.listdir(class_dir) if v.endswith(('.mp4', '.avi', '.mov'))]\n",
    "    for vid in tqdm(videos, desc=f\"Embedding {cls}\"):\n",
    "        vpath = os.path.join(class_dir, vid)\n",
    "        emb = get_video_embedding(vpath, num_frames=num_sample_frames)\n",
    "        if emb is not None:\n",
    "            video_info.append((vpath, cls, emb))\n",
    "\n",
    "print(f\"\\nâœ… Collected embeddings for {len(video_info)} videos.\")\n",
    "\n",
    "# Compare all pairs (cosine similarity)\n",
    "unique_videos = []\n",
    "removed_videos = set()\n",
    "\n",
    "for i, (path_i, cls_i, emb_i) in enumerate(tqdm(video_info, desc=\"Checking duplicates\")):\n",
    "    if path_i in removed_videos:\n",
    "        continue\n",
    "    duplicate_found = False\n",
    "    for j in range(i):\n",
    "        path_j, cls_j, emb_j = video_info[j]\n",
    "        if path_j in removed_videos:\n",
    "            continue\n",
    "        sim = F.cosine_similarity(emb_i, emb_j, dim=0).item()\n",
    "        if sim >= similarity_threshold:\n",
    "            duplicate_found = True\n",
    "            removed_videos.add(path_i)\n",
    "            break\n",
    "    if not duplicate_found:\n",
    "        unique_videos.append((path_i, cls_i))\n",
    "\n",
    "print(f\"\\nâœ… Unique videos kept: {len(unique_videos)} / {len(video_info)}\")\n",
    "\n",
    "# Copy unique videos to new_dataset/\n",
    "for vpath, cls in tqdm(unique_videos, desc=\"Copying unique videos\"):\n",
    "    dst_dir = os.path.join(output_root, cls)\n",
    "    ensure_dir(dst_dir)\n",
    "    shutil.copy2(vpath, dst_dir)\n",
    "\n",
    "print(f\"\\nðŸŽ‰ Finished! Unique videos saved in: {output_root}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd411b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cellula_cv3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
